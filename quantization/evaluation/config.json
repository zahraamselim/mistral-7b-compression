{
  "experiment_info": {
    "base_model": "mistralai/Mistral-7B-v0.1",
    "focus": "RAG performance evaluation on quantized models",
    "primary_metrics": [
      "attention_preservation",
      "context_degradation",
      "attention_drift",
      "reading_comprehension_accuracy",
      "model_efficiency"
    ]
  },
  "performance_benchmarks": {
    "time_performance": {
      "description": "Measures latency, TTFT, and throughput",
      "parameters": {
        "num_warmup": 3,
        "num_runs": 10,
        "max_new_tokens": 128
      },
      "estimated_time_min": 3
    },
    "space_performance": {
      "description": "Measures model size, memory usage, and efficiency",
      "parameters": {
        "batch_size": 1,
        "sequence_length": 2048,
        "reset_stats": true
      },
      "estimated_time_min": 1
    },
    "perplexity": {
      "description": "Language modeling capability on standard text",
      "parameters": {
        "dataset_name": "wikitext",
        "dataset_config": "wikitext-2-raw-v1",
        "split": "test",
        "max_samples": 100,
        "max_length": 512
      },
      "estimated_time_min": 1
    }
  },
  "custom_rag_benchmarks": {
    "attention": {
      "description": "Unified attention evaluation: preservation and drift",
      "speed": "fast",
      "parameters": {
        "num_samples": 40,
        "generation_positions": [1, 5, 20],
        "num_documents": 5
      },
      "estimated_time_min": 20
    },
    "context": {
      "description": "Unified context evaluation: degradation and position effects",
      "speed": "fast",
      "parameters": {
        "samples_per_length": 25,
        "context_lengths": [512, 2048, 4096],
        "answer_positions": ["middle"]
      },
      "estimated_time_min": 15
    }
  },
  "lm_eval_tasks": {
    "reasoning": {
      "description": "Baseline reasoning capabilities",
      "tasks": ["hellaswag", "winogrande", "piqa", "arc_easy", "arc_challenge"],
      "num_fewshot": 0,
      "estimated_time_min": 15
    },
    "rag_core": {
      "description": "Core RAG tasks - reading comprehension with context",
      "tasks": ["squad", "triviaqa"],
      "num_fewshot": 0,
      "estimated_time_min": 20
    },
    "rag_reasoning": {
      "description": "RAG with complex reasoning over context",
      "tasks": ["drop", "race"],
      "num_fewshot": 3,
      "estimated_time_min": 12
    },
    "rag_verification": {
      "description": "Fact verification from passages",
      "tasks": ["boolq"],
      "num_fewshot": 0,
      "estimated_time_min": 5
    }
  },
  "evaluation_protocol": {
    "execution_order": [
      "time_performance",
      "space_performance",
      "perplexity",
      "attention",
      "context_degradation",
      "lm_eval_tasks"
    ],
    "estimated_total_time_min": 60
  }
}
