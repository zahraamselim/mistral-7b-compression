\section{Results}

This section presents empirical results across three evaluation dimensions: computational efficiency (Section \ref{sec:efficiency}), task performance quality (Section \ref{sec:quality}), and RAG-specific capabilities (Section \ref{sec:rag}). All measurements are conducted on NVIDIA Tesla T4 (16GB VRAM) using Mistral-7B-v0.1 as the base model.

\subsection{Computational Efficiency Analysis}
\label{sec:efficiency}

\subsubsection{Latency Metrics}

\begin{table}[H]
\centering
\caption{Latency measurements across quantization methods}
\label{tab:latency_methods}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Latency} & \textbf{TTFT} & \textbf{Prefill} & \textbf{Decode} & \textbf{Speedup} \\
 & \textbf{(ms/tok)} & \textbf{(ms)} & \textbf{(ms)} & \textbf{(ms/tok)} & \textbf{vs FP16} \\
\midrule
FP16 & & & & & 1.00$\times$ \\
NF4 & & & & & \\
GPTQ & & & & & \\
AWQ & & & & & \\
HQQ & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Latency measurements: GPTQ calibration dataset comparison}
\label{tab:latency_calibration}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Calibration} & \textbf{Latency} & \textbf{TTFT} & \textbf{Prefill} & \textbf{Decode} & \textbf{Speedup} \\
\textbf{Dataset} & \textbf{(ms/tok)} & \textbf{(ms)} & \textbf{(ms)} & \textbf{(ms/tok)} & \textbf{vs FP16} \\
\midrule
GPTQ-WikiText & & & & & \\
GPTQ-RAG & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Memory and Compression}

\begin{table}[H]
\centering
\caption{Memory utilization and compression metrics}
\label{tab:memory_methods}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Model Size} & \textbf{Peak Memory} & \textbf{Bits/} & \textbf{Compression} & \textbf{Memory} \\
 & \textbf{(GB)} & \textbf{(MB)} & \textbf{Param} & \textbf{Ratio} & \textbf{Efficiency} \\
\midrule
FP16 & 13.49 & & 16.0 & 1.00$\times$ & \\
NF4 & & & 4.0 & & \\
GPTQ & & & 4.0 & & \\
AWQ & & & 4.0 & & \\
HQQ & & & 4.0 & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Memory utilization: GPTQ calibration dataset comparison}
\label{tab:memory_calibration}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Calibration} & \textbf{Model Size} & \textbf{Peak Memory} & \textbf{Bits/} & \textbf{Compression} & \textbf{Memory} \\
\textbf{Dataset} & \textbf{(GB)} & \textbf{(MB)} & \textbf{Param} & \textbf{Ratio} & \textbf{Efficiency} \\
\midrule
GPTQ-WikiText & & & 4.0 & & \\
GPTQ-RAG & & & 4.0 & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Throughput}

\begin{table}[H]
\centering
\caption{Generation throughput across quantization methods}
\label{tab:throughput_methods}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Throughput} & \textbf{Total Tokens} & \textbf{Total Time} & \textbf{Throughput} \\
 & \textbf{(tok/s)} & \textbf{Generated} & \textbf{(s)} & \textbf{vs FP16} \\
\midrule
FP16 & & & & 1.00$\times$ \\
NF4 & & & & \\
GPTQ & & & & \\
AWQ & & & & \\
HQQ & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Generation throughput: GPTQ calibration dataset comparison}
\label{tab:throughput_calibration}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Calibration} & \textbf{Throughput} & \textbf{Total Tokens} & \textbf{Total Time} & \textbf{Throughput} \\
\textbf{Dataset} & \textbf{(tok/s)} & \textbf{Generated} & \textbf{(s)} & \textbf{vs FP16} \\
\midrule
GPTQ-WikiText & & & & \\
GPTQ-RAG & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Batch Inference Scaling}

\begin{table}[H]
\centering
\caption{Batch throughput scaling (samples/second)}
\label{tab:batch_methods}
\small
\begin{tabular}{lccccccc}
\toprule
\textbf{Method} & \textbf{Batch=1} & \textbf{Batch=2} & \textbf{Batch=4} & \textbf{Batch=8} & \textbf{Optimal} & \textbf{Optimal} & \textbf{Scaling} \\
 & & & & & \textbf{Batch} & \textbf{Throughput} & \textbf{Efficiency} \\
\midrule
FP16 & & & & & & & \\
NF4 & & & & & & & \\
GPTQ & & & & & & & \\
AWQ & & & & & & & \\
HQQ & & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Batch throughput scaling: GPTQ calibration dataset comparison}
\label{tab:batch_calibration}
\small
\begin{tabular}{lccccccc}
\toprule
\textbf{Calibration} & \textbf{Batch=1} & \textbf{Batch=2} & \textbf{Batch=4} & \textbf{Batch=8} & \textbf{Optimal} & \textbf{Optimal} & \textbf{Scaling} \\
\textbf{Dataset} & & & & & \textbf{Batch} & \textbf{Throughput} & \textbf{Efficiency} \\
\midrule
GPTQ-WikiText & & & & & & & \\
GPTQ-RAG & & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Energy Consumption}

\begin{table}[H]
\centering
\caption{Energy consumption estimates}
\label{tab:energy_methods}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Energy/Token} & \textbf{TDP} & \textbf{Energy} & \textbf{Est. Cost} \\
 & \textbf{(mJ)} & \textbf{(W)} & \textbf{Efficiency vs FP16} & \textbf{(\$/1M tokens)} \\
\midrule
FP16 & & 70 & 1.00$\times$ & \\
NF4 & & 70 & & \\
GPTQ & & 70 & & \\
AWQ & & 70 & & \\
HQQ & & 70 & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Energy consumption: GPTQ calibration dataset comparison}
\label{tab:energy_calibration}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Calibration} & \textbf{Energy/Token} & \textbf{TDP} & \textbf{Energy} & \textbf{Est. Cost} \\
\textbf{Dataset} & \textbf{(mJ)} & \textbf{(W)} & \textbf{Efficiency vs FP16} & \textbf{(\$/1M tokens)} \\
\midrule
GPTQ-WikiText & & 70 & & \\
GPTQ-RAG & & 70 & & \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Task Performance Analysis}
\label{sec:quality}

\subsubsection{Language Modeling: Perplexity}

\begin{table}[H]
\centering
\caption{Perplexity on WikiText-2 test set}
\label{tab:perplexity_methods}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Perplexity} & \textbf{Loss} & \textbf{Delta PPL} & \textbf{Degradation} \\
 & & & \textbf{vs FP16} & \textbf{(\%)} \\
\midrule
FP16 & & & 0.00 & 0.0\% \\
NF4 & & & & \\
GPTQ & & & & \\
AWQ & & & & \\
HQQ & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Perplexity: GPTQ calibration dataset comparison}
\label{tab:perplexity_calibration}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Calibration} & \textbf{Perplexity} & \textbf{Loss} & \textbf{Delta PPL} & \textbf{Degradation} \\
\textbf{Dataset} & & & \textbf{vs FP16} & \textbf{(\%)} \\
\midrule
GPTQ-WikiText & & & & \\
GPTQ-RAG & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Reasoning Tasks}

\begin{table}[H]
\centering
\caption{Reasoning benchmark performance (0-shot)}
\label{tab:reasoning_methods}
\small
\begin{tabular}{lccccccc}
\toprule
\textbf{Method} & \textbf{Hella-} & \textbf{Wino-} & \textbf{PIQA} & \textbf{ARC-} & \textbf{ARC-} & \textbf{Bool} & \textbf{Avg} \\
 & \textbf{Swag} & \textbf{Grande} & & \textbf{Easy} & \textbf{Chal.} & \textbf{Q} & \\
\midrule
FP16 & & & & & & & \\
NF4 & & & & & & & \\
GPTQ & & & & & & & \\
AWQ & & & & & & & \\
HQQ & & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Reasoning benchmarks: GPTQ calibration dataset comparison}
\label{tab:reasoning_calibration}
\small
\begin{tabular}{lccccccc}
\toprule
\textbf{Calibration} & \textbf{Hella-} & \textbf{Wino-} & \textbf{PIQA} & \textbf{ARC-} & \textbf{ARC-} & \textbf{Bool} & \textbf{Avg} \\
\textbf{Dataset} & \textbf{Swag} & \textbf{Grande} & & \textbf{Easy} & \textbf{Chal.} & \textbf{Q} & \\
\midrule
GPTQ-WikiText & & & & & & & \\
GPTQ-RAG & & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Knowledge and Mathematical Reasoning}

\begin{table}[H]
\centering
\caption{Knowledge and mathematical reasoning performance}
\label{tab:knowledge_math_methods}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{MMLU} & \textbf{GSM8K} & \textbf{TruthfulQA} & \textbf{Avg} & \textbf{Avg Deg.} \\
 & \textbf{(5-shot)} & \textbf{(5-shot)} & \textbf{(0-shot)} & & \textbf{(\%)} \\
\midrule
FP16 & & & & & 0.0\% \\
NF4 & & & & & \\
GPTQ & & & & & \\
AWQ & & & & & \\
HQQ & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Knowledge and math: GPTQ calibration dataset comparison}
\label{tab:knowledge_math_calibration}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Calibration} & \textbf{MMLU} & \textbf{GSM8K} & \textbf{TruthfulQA} & \textbf{Avg} & \textbf{Avg Deg.} \\
\textbf{Dataset} & \textbf{(5-shot)} & \textbf{(5-shot)} & \textbf{(0-shot)} & & \textbf{(\%)} \\
\midrule
GPTQ-WikiText & & & & & \\
GPTQ-RAG & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{RAG-Focused Reading Comprehension}

\begin{table}[H]
\centering
\caption{RAG-focused reading comprehension tasks}
\label{tab:rag_tasks_methods}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Method} & \textbf{SQuAD} & \textbf{NQ-Open} & \textbf{TriviaQA} & \textbf{DROP} & \textbf{QuAC} & \textbf{Avg} \\
\midrule
FP16 & & & & & & \\
NF4 & & & & & & \\
GPTQ & & & & & & \\
AWQ & & & & & & \\
HQQ & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{RAG-focused tasks: GPTQ calibration dataset comparison}
\label{tab:rag_tasks_calibration}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Calibration} & \textbf{SQuAD} & \textbf{NQ-Open} & \textbf{TriviaQA} & \textbf{DROP} & \textbf{QuAC} & \textbf{Avg} \\
\textbf{Dataset} & & & & & & \\
\midrule
GPTQ-WikiText & & & & & & \\
GPTQ-RAG & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsection{RAG-Specific Performance Analysis}
\label{sec:rag}

\subsubsection{Attention Preservation}

\begin{table}[H]
\centering
\caption{Attention preservation to relevant documents}
\label{tab:attention_preservation_methods}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Method} & \textbf{Precision} & \textbf{Mean} & \textbf{Median} & \textbf{Gini} & \textbf{EM} & \textbf{F1} \\
 & \textbf{@1} & \textbf{Rank} & \textbf{Rank} & \textbf{Coeff} & \textbf{Acc} & \textbf{Score} \\
\midrule
FP16 & & & & & & \\
NF4 & & & & & & \\
GPTQ & & & & & & \\
AWQ & & & & & & \\
HQQ & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Attention preservation: GPTQ calibration dataset comparison}
\label{tab:attention_preservation_calibration}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Calibration} & \textbf{Precision} & \textbf{Mean} & \textbf{Median} & \textbf{Gini} & \textbf{EM} & \textbf{F1} \\
\textbf{Dataset} & \textbf{@1} & \textbf{Rank} & \textbf{Rank} & \textbf{Coeff} & \textbf{Acc} & \textbf{Score} \\
\midrule
GPTQ-WikiText & & & & & & \\
GPTQ-RAG & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Context Degradation Analysis}

\begin{table}[H]
\centering
\caption{Accuracy degradation with increasing context length}
\label{tab:context_degradation_methods}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Slope per} & \textbf{R-squared} & \textbf{Cliff Point} & \textbf{Signif.} & \textbf{Position} \\
 & \textbf{1K tokens} & & \textbf{(tokens)} & \textbf{Deg.?} & \textbf{Effect?} \\
\midrule
FP16 & & & & & \\
NF4 & & & & & \\
GPTQ & & & & & \\
AWQ & & & & & \\
HQQ & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Context degradation: GPTQ calibration dataset comparison}
\label{tab:context_degradation_calibration}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Calibration} & \textbf{Slope per} & \textbf{R-squared} & \textbf{Cliff Point} & \textbf{Signif.} & \textbf{Position} \\
\textbf{Dataset} & \textbf{1K tokens} & & \textbf{(tokens)} & \textbf{Deg.?} & \textbf{Effect?} \\
\midrule
GPTQ-WikiText & & & & & \\
GPTQ-RAG & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Context Length Breakdown}

\begin{table}[H]
\centering
\caption{Accuracy by context length (F1 score)}
\label{tab:context_length_methods}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{512 tok} & \textbf{1024 tok} & \textbf{2048 tok} & \textbf{4096 tok} & \textbf{Degradation} \\
 & & & & & \textbf{512 to 4096} \\
\midrule
FP16 & & & & & \\
NF4 & & & & & \\
GPTQ & & & & & \\
AWQ & & & & & \\
HQQ & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Context length breakdown: GPTQ calibration comparison}
\label{tab:context_length_calibration}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Calibration} & \textbf{512 tok} & \textbf{1024 tok} & \textbf{2048 tok} & \textbf{4096 tok} & \textbf{Degradation} \\
\textbf{Dataset} & & & & & \textbf{512 to 4096} \\
\midrule
GPTQ-WikiText & & & & & \\
GPTQ-RAG & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Attention Drift During Generation}

\begin{table}[H]
\centering
\caption{Attention stability during generation}
\label{tab:attention_drift_methods}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Method} & \textbf{Mean} & \textbf{Max} & \textbf{Drift from} & \textbf{Drift-F1} & \textbf{Drift@} & \textbf{Drift@} \\
 & \textbf{Drift} & \textbf{Drift} & \textbf{Relevant} & \textbf{Corr (r)} & \textbf{Correct} & \textbf{Wrong} \\
\midrule
FP16 & & & & & & \\
NF4 & & & & & & \\
GPTQ & & & & & & \\
AWQ & & & & & & \\
HQQ & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Attention drift: GPTQ calibration dataset comparison}
\label{tab:attention_drift_calibration}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Calibration} & \textbf{Mean} & \textbf{Max} & \textbf{Drift from} & \textbf{Drift-F1} & \textbf{Drift@} & \textbf{Drift@} \\
\textbf{Dataset} & \textbf{Drift} & \textbf{Drift} & \textbf{Relevant} & \textbf{Corr (r)} & \textbf{Correct} & \textbf{Wrong} \\
\midrule
GPTQ-WikiText & & & & & & \\
GPTQ-RAG & & & & & & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Attention-Quality Correlation Analysis}

\begin{table}[H]
\centering
\caption{Correlation between attention metrics and answer quality}
\label{tab:attention_quality_methods}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Prec@1 vs F1} & \textbf{Rank vs F1} & \textbf{High Attn} & \textbf{Low Attn} \\
 & \textbf{(Pearson r)} & \textbf{(Spearman rho)} & \textbf{Correct (\%)} & \textbf{Correct (\%)} \\
\midrule
FP16 & & & & \\
NF4 & & & & \\
GPTQ & & & & \\
AWQ & & & & \\
HQQ & & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Attention-quality correlation: GPTQ calibration comparison}
\label{tab:attention_quality_calibration}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Calibration} & \textbf{Prec@1 vs F1} & \textbf{Rank vs F1} & \textbf{High Attn} & \textbf{Low Attn} \\
\textbf{Dataset} & \textbf{(Pearson r)} & \textbf{(Spearman rho)} & \textbf{Correct (\%)} & \textbf{Correct (\%)} \\
\midrule
GPTQ-WikiText & & & & \\
GPTQ-RAG & & & & \\
\bottomrule
\end{tabular}
\end{table}
