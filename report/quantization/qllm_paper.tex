\documentclass[11pt,a4paper]{article}
% \documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts

% Packages
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{listings}
\usepackage{url}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{adjustbox}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=1in]{geometry}

% Column spacing - more breathing room between columns
\setlength{\columnsep}{0.25in}
\setlength{\parindent}{0pt}

% Table spacing - makes tables more readable
\renewcommand{\arraystretch}{1.3}

% Section spacing - better vertical rhythm
\titlespacing*{\section}{0pt}{12pt plus 4pt minus 2pt}{6pt plus 2pt minus 2pt}
\titlespacing*{\subsection}{0pt}{10pt plus 3pt minus 2pt}{4pt plus 2pt minus 2pt}
\titlespacing*{\subsubsection}{0pt}{8pt plus 2pt minus 2pt}{3pt plus 2pt minus 2pt}

% Paragraph spacing
\setlength{\parskip}{3pt}

% List spacing - cleaner itemize/enumerate
\setlist{itemsep=2pt, parsep=2pt, topsep=4pt}

% Code listing configuration
\lstset{
  language=Python,
  basicstyle=\ttfamily\scriptsize,
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{green!50!black},
  stringstyle=\color{red!70!black},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  aboveskip=10pt,
  belowskip=10pt,
  xleftmargin=15pt,
  xrightmargin=5pt,
  framexleftmargin=12pt
}

% Better spacing around equations
\setlength{\abovedisplayskip}{8pt plus 2pt minus 4pt}
\setlength{\belowdisplayskip}{8pt plus 2pt minus 4pt}
\setlength{\abovedisplayshortskip}{4pt plus 2pt minus 2pt}
\setlength{\belowdisplayshortskip}{4pt plus 2pt minus 2pt}

% BibTeX definition
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

% \title{Comprehensive Evaluation of Quantization Methods for Edge LLM Deployment\\
% \thanks{This work was conducted at Egypt-Japan University of Science and Technology (E-JUST).}
% }

% \author{\IEEEauthorblockN{Zahraa Selim, Menna Hamed, Wesam Ahmed, Sohyla Said, Sara Basheer, and Rami Zewail}
% \IEEEauthorblockA{\textit{Computer Science and Engineering Department}\\
% \textit{Egypt-Japan University of Science and Technology (E-JUST)}\\
% Alexandria, Egypt\\
% \{zahraa.selim, menna.hamed, rami.zewail\}@ejust.edu.eg}
% }

\title{\LARGE \textbf{Comprehensive Evaluation of Quantization Methods\\for Edge LLM Deployment with RAG Focus}}

\author{
Zahraa Selim, Menna Hamed, Wesam Ahmed,\\
Sohyla Said, Sara Basheer, Rami Zewail\\
\\
\textit{Computer Science and Engineering Department}\\
\textit{Egypt-Japan University of Science and Technology (E-JUST)}\\
Alexandria, Egypt\\
\texttt{\{zahraa.selim, menna.hamed, rami.zewail\}@ejust.edu.eg}
}

\maketitle

\begin{abstract}
The deployment of Large Language Models (LLMs) on resource-constrained edge hardware is significantly impeded by memory bandwidth bottlenecks. Post-Training Quantization (PTQ) has emerged as a standard compression paradigm, yet comprehensive benchmarking of modern quantization methods on consumer-grade hardware remains limited. This study conducts a rigorous empirical evaluation of five advanced quantization techniques (NF4, GPTQ, AWQ, HQQ, and AutoRound) applied to Mistral-7B on NVIDIA Tesla T4 hardware. Our findings indicate that NormalFloat 4-bit (NF4) quantization establishes an optimal Pareto frontier, achieving 3.6Ã— memory reduction while maintaining superior task performance and hardware compatibility. Critically, we identify that hardware-algorithm compatibility significantly influences performance, with distribution-based methods (NF4) providing superior stability on Turing architectures compared to kernel-dependent methods (GPTQ, HQQ) that may experience severe fallback overhead. Our analysis reveals task-dependent sensitivity to quantization, where mathematical reasoning degrades by 25\% while knowledge retrieval remains robust. We provide prescriptive deployment guidelines identifying NF4 as the superior strategy for balancing throughput, energy efficiency, and task performance on edge hardware.
\end{abstract}

% \begin{IEEEkeywords}
% LLM Quantization, Edge Computing, Mistral-7B, Efficiency Benchmarking, Post-Training Quantization, Hardware Compatibility
% \end{IEEEkeywords}

\input{sections/introduction}

\input{sections/related_work}

\input{sections/methodology}

\newpage
\input{sections/results}

% \input{sections/discussion}

% \input{sections/conclusion}

% \input{sections/acknowledgement}

% \bibliographystyle{IEEEtran}
% \bibliography{references}

\end{document}